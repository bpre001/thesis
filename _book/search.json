[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modeling Water Inflows",
    "section": "",
    "text": "Abstract\nThis thesis investigates the application of two multivariate time series modeling techniques to analyse, parameterise and simulate hydrological inflows for New Zealand’s five major dams - Hawea, Manapouri, Pukaki, Tekapo and Taupo. Hydrological inflow simulation is important for determining the value of water and water storage used in generating hydroelectric power and is a key input to modelling New Zealand’s electricity market.\nKeywords: Multivariate Time Series Modeling, Hydrological Inflows, Dam Reservoirs, Forecasting, Simulation, New Zealand, Water Resource Management, Water Valuation, Version Control, GIT.",
    "crumbs": [
      "Abstract"
    ]
  },
  {
    "objectID": "milestones.html",
    "href": "milestones.html",
    "title": "Milestones",
    "section": "",
    "text": "Introduction and Background (Feb - Mar 2024)\nThe thesis will commence with a description of the nature of water inflow in the NZ hydroelectric generation scheme and its significant impact on the NZ electricity market model (in terms of both price and reliability). The introduction will provide an overview of the significance of hydrological inflow simulation for dam reservoir management, energy production, and water resource planning. The background section will outline the industry-adopted non-parametric technique of using weekly historical inflow data from April 1931. Using dynamic programming techniques, these data are used to create water valuation tables.\nThis technique is computationally intensive and as a consequence, alternative shorter inflow data (from history or simulated) would significantly improve market model run times. These shorter inflow data sets are the focus of this thesis. Ultimately we seek to recommend a preferred technique for generating and choosing a shorter inflow data set to be utilised by EnergyLink’s water valuation model which is in turn an input to EnergyLink’s market model.",
    "crumbs": [
      "Milestones"
    ]
  },
  {
    "objectID": "milestones.html#data-collection-and-exploration-apr---may-2024",
    "href": "milestones.html#data-collection-and-exploration-apr---may-2024",
    "title": "Milestones",
    "section": "Data Collection and Exploration (Apr - May 2024)",
    "text": "Data Collection and Exploration (Apr - May 2024)\nThis phase will involve the collection of relevant datasets. This data has been obtained from EnergyLink and has been processed and cleaned for use in their proprietary models. Climatological data pertinent to NZ’s five hydroelectric schemes (e.g. teleconnections and precipitation measurements will be sourced from NIWA). The data will be explored to identify patterns, trends, distributions and correlations between variables. The goal is to gain insights into the relationships between meso- and macro-scale weather conditions and hydrological inflows.",
    "crumbs": [
      "Milestones"
    ]
  },
  {
    "objectID": "milestones.html#model-development-and-implementation-jun---jul-2024",
    "href": "milestones.html#model-development-and-implementation-jun---jul-2024",
    "title": "Milestones",
    "section": "Model Development and Implementation (Jun - Jul 2024)",
    "text": "Model Development and Implementation (Jun - Jul 2024)\nIn this phase of the thesis we are generating the alternate (shorter) inflow data sets.\nThere are three alternate inflow data sets: 1. By subsetting directly from the full historical data set in the form of rolling 30 year contiguous data subsets.\n2. Simulating from the full historical data set using a Moving Block Bootstrap (‘MBB’). The MBB will be used to generate 30 year inflow data subsets and is a resampling technique that preserves the temporal correlation structure of the original data.\n3. Generating simulations from a Vector Auto Regression with exogenous variates (‘VARx’) model. The VARx model will be trained on the full historical data set and will be used to generate 30 year inflow data subsets.\n\nThese will be developed in a univariate and multivariate context. The univariate context will involve the development of a univariate time series model for a single scheme inflow. The multivariate context will involve the development of a multivariate time series model for all five schemes’ inflow data.",
    "crumbs": [
      "Milestones"
    ]
  },
  {
    "objectID": "milestones.html#experimentation-and-evaluation-jun---sep-2024",
    "href": "milestones.html#experimentation-and-evaluation-jun---sep-2024",
    "title": "Milestones",
    "section": "Experimentation and Evaluation (Jun - Sep 2024)",
    "text": "Experimentation and Evaluation (Jun - Sep 2024)\nIn this phase, the alternate inflow data sets will be uploaded into EnergyLink’s water valuation model and a water valuation table will be produced. We will develop relevant performance metrics when compared to the water valuation table produced using the full historical data set. Measures like Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) will be used when determining “best fit”. We will also consider the computational time taken to generate the water valuation table. The goal is to determine which of the alternate data sets generates the most similar water valuation table.",
    "crumbs": [
      "Milestones"
    ]
  },
  {
    "objectID": "milestones.html#final-analysis-and-conclusion-jul---oct-2024",
    "href": "milestones.html#final-analysis-and-conclusion-jul---oct-2024",
    "title": "Milestones",
    "section": "Final Analysis and Conclusion (Jul - Oct 2024)",
    "text": "Final Analysis and Conclusion (Jul - Oct 2024)\nThe final stage of the thesis will involve synthesizing the results, interpreting findings, and making a recommendation of which alternate inflow data set should be used when computing water valuation tables.\nRecommendations for further research, potential applications, and practical implications of the study will be discussed.",
    "crumbs": [
      "Milestones"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This thesis investigates the application of two multivariate time series modeling techniques to analyse, parameterise and simulate hydrological inflows for New Zealand’s five major dams - Hawea, Manapouri, Pukaki, Tekapo and Taupo. Hydrological inflow simulation is important for determining the value of water and water storage used in generating hydroelectric power and is a key input to modelling New Zealand’s electricity market.\nTraditionally, water valuation models take all of the historic inflow data available and simulate variablity of flow for all of the schemes contemporaneously by cycling through the historical data from a starting week in each year. This method is non-parametric and by construction preserves the seasonal, autoregressive and covariance features of the original data series.\nHowever, this method is computationally intensive as the historic data set increases in size (currently 91 years * 5 schemes * 52 weeks), and soon to be 92 years… Indeed, we estimate that the number of calculations required to complete one 25 year forecast to be ___________________________________.\nIn the past, one computational workaround has been to reduce the historical inflow sample to approximately 30 years (WY1950 - WY1979 are often used) which has the impact of reducing calculations by approximately 2/3, which is significant. An important question is whether this contiguous subset of the historical inflow data is a fair representation of the original data set (or indeed is there a “better” contiguous subset?).\nThis thesis explores two alternative approaches replacing the 30 year subset of contiguous historical data with a 30 year simulation of inflow data that has been derived from all of the available historical data. We would want to compare the performance of these simulations and their ability to capture and emulate temporal dependencies and interrelationships among inflow variables. Model performance metrics, including accuracy, precision, and reliability, are used to evaluate and validate these models, and ultimately to make a recommendation of which 30 year inflow data series works “best”.\nThe initial analysis will only consider one scheme and build a framework to determine the best performing model. The analysis will then be extended to include vector representation of all five schemes.\nThe two multivariate time series models that I will build include a non-parametric Classical Additive Decomposition with Moving Block Bootstrapping and a parametric Vector Auto Regression Intergrated Moving Average with Exogeneous Variates (VARIMAx).\nResults from the study demonstrate the effectiveness of multivariate time series models in capturing the dynamic nature of hydrological inflows for New Zealand’s major dams responsible for approximately 60% of Neq Zealand’s electricity supply. The thesis will contributes insights into the factors influencing inflow variability and provides a framework for enhancing water resource management strategies through improved forecasting techniques.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "2  Exploration",
    "section": "",
    "text": "2.1 Preface\nThe scope of this thesis is to develop a statistical model to describe and simulate water inflow to New Zealand’s 5 major hydro schemes. Combined, these 5 schemes are a major source of renewable energy in New Zealand, responsible for approximately (60%) of all electricity generated and reliability to the New Zealand grid.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exploration</span>"
    ]
  },
  {
    "objectID": "exploration.html#data",
    "href": "exploration.html#data",
    "title": "2  Exploration",
    "section": "2.2 Data",
    "text": "2.2 Data\nEnergy Link have provided me with weekly inflow data for each of the 5 schemes from 1931 to 2024. The data is in the form of cumulative inflow in cubic meters per second (cumecs) for each week of the year. The data is clean and complete, with no missing values.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exploration</span>"
    ]
  },
  {
    "objectID": "exploration.html#analysis",
    "href": "exploration.html#analysis",
    "title": "2  Exploration",
    "section": "2.3 Analysis",
    "text": "2.3 Analysis\n\n## function to determine 1st Monday preceeding or on April 1 of a given year\nfirstMonday &lt;- function(year) {\n  # Create April 1 of the given year\n  april_first &lt;- ymd(paste(year, \"04-01\"))\n  \n  # Check if April 1 is already a Monday, if not, find the preceding Monday\n  if (wday(april_first, week_start = 1) != 1) {  # 1 represents Monday\n    april_first &lt;- april_first - days(wday(april_first, week_start = 1) - 1)\n  }\n  \n  return(april_first)\n}\n\n## inflow data load, clean and save as .rds\n\n# cumec_long &lt;- read_csv(\"cumec.csv\") |&gt;\n#     pivot_longer(cols = -c(Scheme,Unit,Year), names_to = \"Week\", values_to = \"Inflow\") |&gt;\n#     rowwise() |&gt;\n#     mutate(Week = as.numeric(str_remove(Week, \"Week\")),\n#            Date = firstMonday(Year) + weeks(Week - 1)\n#            ) |&gt;\n#     filter(!(Date == firstMonday(Year+1) & Week == 53)) |&gt; # removes duplicates\n#     filter(Date &lt;= dmy(31032023)) |&gt; \n#     select(Date,Scheme,Inflow)\n# \n# \n# \n#  cumec_wide &lt;- cumec_long |&gt;\n#    pivot_wider(names_from = Scheme,\n#                values_from = Inflow)\n\n## save cumec_long and cumec_wide tibbles as .rds objects\n # saveRDS(cumec_long, file = \"cumec_long.rds\")\n # saveRDS(cumec_wide, file = \"cumec_wide.rds\")\n\n\n# reload clean wide data sets:\n\ncumec_wide &lt;- readRDS(\"cumec_wide.rds\") |&gt; \n  mutate(Type = \"Actual\") |&gt; \n  select(Date, Type, everything())\n\nglimpse(cumec_wide)\n\nRows: 4,801\nColumns: 7\n$ Date      &lt;date&gt; 1931-03-30, 1931-04-06, 1931-04-13, 1931-04-20, 1931-04-27,…\n$ Type      &lt;chr&gt; \"Actual\", \"Actual\", \"Actual\", \"Actual\", \"Actual\", \"Actual\", …\n$ Hawea     &lt;dbl&gt; 87.70000, 53.60000, 49.40000, 34.30000, 25.40000, 16.40000, …\n$ Manapouri &lt;dbl&gt; 323.0000, 296.0000, 266.0000, 237.0000, 213.0000, 199.0000, …\n$ Pukaki    &lt;dbl&gt; 285.00000, 139.00000, 95.00000, 74.00000, 53.00000, 71.00000…\n$ Tekapo    &lt;dbl&gt; 189.00000, 87.00000, 59.00000, 47.00000, 32.00000, 45.00000,…\n$ Taupo     &lt;dbl&gt; 112.7000, 110.2000, 163.2000, 162.1000, 161.7000, 102.0000, …\n\nminDate &lt;- min(cumec_wide$Date)\nmaxDate &lt;- max(cumec_wide$Date)\n\n\ncumec_wide_pre &lt;- cumec_wide |&gt; \n  filter(Date &gt;= max(Date) - years(2)) |&gt; \n  mutate(Date = minDate + (row_number() - (n() + 1)) * 7,\n         Type = \"Pre\") \n\ncumec_wide_post &lt;- cumec_wide |&gt; \n  filter(Date &lt;= min(Date) + years(26)) |&gt; \n  mutate(Date = maxDate + row_number() * 7,\n         Type = \"Post\") \n\ncumec_wide_ts &lt;- cumec_wide_pre |&gt; \n  bind_rows(cumec_wide) |&gt; \n  bind_rows(cumec_wide_post) |&gt; \n  as_tsibble(index = Date)\n\n# produce graphs of time series, ACF and PACF for Hawea\n\ncumec_wide_ts |&gt;\n  filter(Type == \"Actual\") |&gt;\n  gg_tsdisplay(Hawea, plot_type = \"partial\")\n\n\n\n\n\n\n\n# pull lambda coefficients for Box-Cox (\"bc\") transformation\n\nlambdaHawea &lt;- cumec_wide_ts |&gt; \n  filter(Type == \"Actual\") |&gt;\n  features(Hawea, guerrero) |&gt; \n  pull()\n\nlambdaManapouri &lt;- cumec_wide_ts |&gt; \n  filter(Type == \"Actual\") |&gt;\n  features(Manapouri, guerrero) |&gt; \n  pull()\n\nlambdaPukaki &lt;- cumec_wide_ts |&gt; \n  filter(Type == \"Actual\") |&gt;\n  features(Pukaki, guerrero) |&gt; \n  pull()\n\nlambdaTaupo &lt;- cumec_wide_ts |&gt; \n  filter(Type == \"Actual\") |&gt;\n  features(Taupo, guerrero) |&gt; \n  pull()\n\nlambdaTekapo &lt;- cumec_wide_ts |&gt; \n  filter(Type == \"Actual\") |&gt;\n  features(Tekapo, guerrero) |&gt; \n  pull()\n\n\n# mutate cumec_wide_ts to include Box-Cox transformed inflow data\ncumec_wide_ts &lt;- cumec_wide_ts |&gt; \n  mutate(bcHawea = box_cox(Hawea, lambdaHawea),\n         bcManapouri = box_cox(Manapouri, lambdaManapouri),\n         bcPukaki = box_cox(Pukaki, lambdaPukaki),\n         bcTaupo = box_cox(Taupo, lambdaTaupo),\n         bcTekapo = box_cox(Tekapo, lambdaTekapo)\n         ) \n\n# graph Box-Cox transformed inflow data with ACF and PACF\ncumec_wide_ts |&gt;\n  filter(Type == \"Actual\",\n         Date &gt;= dmy(01012001)) |&gt;\n  gg_tsdisplay(bcHawea, plot_type = \"partial\") + \n  labs(title = \"Time series display of Box-Cox Transformed Hawea Inflow\",\n       x = \"Year\",\n       y = \"Transformed Inflow\")\n\n\n\n\n\n\n\ncumec_wide_ts |&gt;\n  filter(Type == \"Actual\",\n         Date &gt;= dmy(01012001)) |&gt;\n  gg_tsdisplay(bcManapouri, plot_type = \"partial\") + \n  labs(title = \"Time series display of Box-Cox Transformed Manapouri Inflow\",\n       x = \"Year\",\n       y = \"Transformed Inflow\")\n\n\n\n\n\n\n\ncumec_wide_ts |&gt;\n  filter(Type == \"Actual\",\n         Date &gt;= dmy(01012001)) |&gt;\n  gg_tsdisplay(bcPukaki, plot_type = \"partial\") + \n  labs(title = \"Time series display of Box-Cox Transformed Pukaki Inflow\",\n       x = \"Year\",\n       y = \"Transformed Inflow\")\n\n\n\n\n\n\n\ncumec_wide_ts |&gt;\n  filter(Type == \"Actual\",\n         Date &gt;= dmy(01012001)) |&gt;\n  gg_tsdisplay(bcTaupo, plot_type = \"partial\") + \n  labs(title = \"Time series display of Box-Cox Transformed Taupo Inflow\",\n       x = \"Year\",\n       y = \"Transformed Inflow\")\n\n\n\n\n\n\n\ncumec_wide_ts |&gt;\n  filter(Type == \"Actual\",\n         Date &gt;= dmy(01012001)) |&gt;\n  gg_tsdisplay(bcTekapo, plot_type = \"partial\") + \n  labs(title = \"Time series display of Box-Cox Transformed Tekapo Inflow\",\n       x = \"Year\",\n       y = \"Transformed Inflow\")\n\n\n\n\n\n\n\n\n\n# histograms of inflow data for all 5 schemes\n\nglimpse(cumec_wide_ts)\n\nRows: 6,263\nColumns: 12\n$ Date        &lt;date&gt; 1929-03-25, 1929-04-01, 1929-04-08, 1929-04-15, 1929-04-2…\n$ Type        &lt;chr&gt; \"Pre\", \"Pre\", \"Pre\", \"Pre\", \"Pre\", \"Pre\", \"Pre\", \"Pre\", \"P…\n$ Hawea       &lt;dbl&gt; 15.92, 95.85, 51.31, 47.03, 39.46, 103.38, 65.48, 59.69, 4…\n$ Manapouri   &lt;dbl&gt; 198.27, 225.17, 407.84, 517.34, 419.05, 500.44, 432.72, 41…\n$ Pukaki      &lt;dbl&gt; 78.03, 170.28, 110.18, 66.39, 52.56, 170.36, 182.69, 72.05…\n$ Tekapo      &lt;dbl&gt; 48.15, 129.72, 76.60, 48.43, 41.31, 125.71, 105.95, 57.15,…\n$ Taupo       &lt;dbl&gt; 77.38, 131.60, 78.45, 60.76, 54.31, 91.73, 122.31, 66.49, …\n$ bcHawea     &lt;dbl&gt; 2.076314, 2.886956, 2.640064, 2.602894, 2.525815, 2.914611…\n$ bcManapouri &lt;dbl&gt; 3.012717, 3.048427, 3.201600, 3.257122, 3.208090, 3.249555…\n$ bcPukaki    &lt;dbl&gt; 3.688668, 4.225847, 3.930248, 3.573281, 3.403820, 4.226161…\n$ bcTaupo     &lt;dbl&gt; 3.658898, 4.022910, 3.668513, 3.487838, 3.407287, 3.777238…\n$ bcTekapo    &lt;dbl&gt; 2.048392, 2.243512, 2.148794, 2.049756, 2.011253, 2.238373…\n\ncumec_wide_ts |&gt; \n  filter(Type == \"Actual\") |&gt; \n  select(Date, !c(Type,starts_with(\"bc\"))) |&gt;\n  pivot_longer(!Date, names_to = \"Scheme\", values_to = \"Inflow\") |&gt; \n  ggplot(aes(x = Inflow, color = Scheme, fill = Scheme)) +\n  geom_histogram(bins = 50) +\n  facet_wrap(~Scheme, scales = \"free\") +\n  labs(title = \"Inflow for each Scheme\",\n       x = \"Inflow (cumecs)\",\n       y = \"Count\") +\n  theme(legend.position = \"none\",\n        strip.placement = \"outside\")\n\n\n\n\n\n\n\n# histograms of box-cox transformed inflow data for all 5 schemes\n\ncumec_wide_ts |&gt; \n  filter(Type == \"Actual\") |&gt; \n  select(Date, starts_with(\"bc\")) |&gt;\n  pivot_longer(!Date, names_to = \"Scheme\", values_to = \"Inflow\") |&gt; \n  ggplot(aes(x = Inflow, color = Scheme, fill = Scheme)) +\n  geom_histogram(bins = 50) +\n  facet_wrap(~Scheme, scales = \"free\") +\n  labs(title = \"Box-Cox Transformed Inflow for each Scheme\",\n       x = \"Transformed Inflow\",\n       y = \"Count\") +\n  theme(legend.position = \"none\",\n        strip.placement = \"outside\")\n\n\n\n\n\n\n\n# tidy tibble for ggplot\ncumec_long &lt;- as_tibble(cumec_wide_ts) |&gt; \n  filter(Type == \"Actual\") |&gt;\n  select(!Type) |&gt; \n  pivot_longer(!Date, names_to = \"Scheme\", values_to = \"Inflow\")\n\n\n# produce q-q plots to confirm near-normality of Box-Cox transformed inflow data\ncumec_long |&gt; \n  filter(startsWith(Scheme, \"bc\")) |&gt; \n  ggplot(aes(sample = Inflow, color = Scheme)) +\n  geom_qq() +\n  geom_qq_line(color = \"black\") +\n  facet_wrap(~Scheme, ncol = 5) +\n  theme(legend.position = \"none\") +\n  labs(title = \"Normal Q-Q Plots for Box-Cox Transformed Inflows of each Scheme\",\n       x = \"Theoretical Standard Deviation\",\n       y = \"Sample Quantile\")\n\n\n\n\n\n\n\n# look at pairs plot of log(inflows) of 5 schemes\ncumec_wide_ts |&gt; as_tibble() |&gt; \n  select(starts_with(\"bc\")) |&gt; \n  ggpairs(progress = FALSE) +\n  labs(title = \"Pairs Plot for Box-Cox Transformed Inflows of each Scheme\")\n\n\n\n\n\n\n\n# produce seasonal plot of weekly log(inflow) history for 1931 - 2024\ncumec_long |&gt; \n  mutate(Year = year(Date),\n         Week = week(Date)) |&gt; \n  filter(startsWith(Scheme, \"bc\")) |&gt; \n  ggplot(aes(x = Week, y = Inflow, color = Year, alpha = 0.1)) +\n  geom_jitter() +\n  geom_smooth(color = \"red\", method = \"gam\") + \n  facet_wrap(~Scheme) +\n  theme(legend.position = \"none\") +\n  labs(title = \"Seasonal Plots for Box-Cox Transformed Inflow of each Scheme\",\n       x = \"Week (1 - 53)\",\n       y = \"Transformed Inflow\")\n\n`geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\n\n# fit STL model to Box-Cox transformed inflow data\nfit &lt;- cumec_wide_ts |&gt; \n  filter(Type == \"Actual\") |&gt;\n  model(stl = STL(bcPukaki)\n       )\n\nfit |&gt; select(stl) |&gt; components() |&gt; head()  \n\n# A dable: 6 x 7 [7D]\n# Key:     .model [1]\n# :        bcPukaki = trend + season_year + remainder\n  .model Date       bcPukaki trend season_year remainder season_adjust\n  &lt;chr&gt;  &lt;date&gt;        &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n1 stl    1931-03-30     4.56  3.82     0.334       0.404          4.23\n2 stl    1931-04-06     4.09  3.82     0.413      -0.145          3.68\n3 stl    1931-04-13     3.83  3.82     0.265      -0.256          3.56\n4 stl    1931-04-20     3.65  3.82     0.393      -0.557          3.26\n5 stl    1931-04-27     3.41  3.81     0.00317    -0.406          3.41\n6 stl    1931-05-04     3.62  3.81    -0.0722     -0.116          3.69\n\nfit |&gt; select(stl) |&gt; \n  components() |&gt; \n  filter(Date &gt;= dmy(01012000),\n         Date &lt; dmy(01012021))|&gt; \n  autoplot()\n\n\n\n\n\n\n\n\n\n## create object that includes dates and inflows for period you want to bootstrap\nhist &lt;- cumec_wide_ts |&gt; \n  filter(Type == \"Actual\") |&gt; \n  select(Date,bcPukaki)\n\nhist_25 &lt;- hist |&gt; \n  filter(Date &lt;= min(Date) + years(x = 25))\n\n## create bootstrapped sims (2 year block bootstrap of errors)\nboot_stl &lt;- fit |&gt; \n  select(stl) |&gt; \n  generate(new_data = hist_25, times = 10,\n           bootstrap_block_size = 2*52)\n\nglimpse(boot_stl)\n\nRows: 13,050\nColumns: 5\nKey: .model, .rep [10]\n$ .model   &lt;chr&gt; \"stl\", \"stl\", \"stl\", \"stl\", \"stl\", \"stl\", \"stl\", \"stl\", \"stl\"…\n$ .rep     &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"…\n$ Date     &lt;date&gt; 1931-03-30, 1931-04-06, 1931-04-13, 1931-04-20, 1931-04-27, …\n$ bcPukaki &lt;dbl&gt; 4.562747, 4.089285, 3.827256, 3.650954, 3.409922, 3.621410, 3…\n$ .sim     &lt;dbl&gt; 4.021049, 4.229601, 4.066377, 4.529302, 3.912816, 3.668039, 4…\n\ntail(boot_stl)\n\n# A tsibble: 6 x 5 [7D]\n# Key:       .model, .rep [1]\n  .model .rep  Date       bcPukaki  .sim\n  &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 stl    9     1956-02-20     4.00  4.29\n2 stl    9     1956-02-27     3.97  4.16\n3 stl    9     1956-03-05     4.06  3.99\n4 stl    9     1956-03-12     4.10  4.36\n5 stl    9     1956-03-19     3.66  4.56\n6 stl    9     1956-03-26     3.72  4.43\n\nboot_stl |&gt; \n  filter(.model == \"stl\") |&gt; \n  mutate(Quarter = quarter(Date)) |&gt; \n  ggplot(aes(x = .sim, group = as.factor(Quarter))) +\n    geom_density(aes(col = as.factor(Quarter)))\n\n\n\n\n\n\n\nboot_stl |&gt; \n  filter(Date &gt;= dmy(01012000)) |&gt;\n  autoplot(.sim)+\n  autolayer(hist_25, bcPukaki ) +\n  guides(colour = \"none\") +\n  labs(title = \"Bootstrapped series for Pukaki Inflows (2000 - Present)\",\n       y=\"Transformed Inflows\")\n\n\n\n\n\n\n\ntail(boot_stl) \n\n# A tsibble: 6 x 5 [7D]\n# Key:       .model, .rep [1]\n  .model .rep  Date       bcPukaki  .sim\n  &lt;chr&gt;  &lt;chr&gt; &lt;date&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 stl    9     1956-02-20     4.00  4.29\n2 stl    9     1956-02-27     3.97  4.16\n3 stl    9     1956-03-05     4.06  3.99\n4 stl    9     1956-03-12     4.10  4.36\n5 stl    9     1956-03-19     3.66  4.56\n6 stl    9     1956-03-26     3.72  4.43\n\nboot_stl |&gt; \n  select(.sim) |&gt; \n  filter(Date &gt;= dmy(01012000),\n         Date &lt; dmy(01012021))|&gt; \n  autoplot() +\n  autolayer(hist, bcPukaki )\n\nPlot variable not specified, automatically selected `.vars = .sim`\n\n\n\n\n\n\n\n\n\n\n## create a wide object of simulated years for each scheme\n## \n\nyears &lt;- 1931:1935\nweeks &lt;- 0:(25*52)\n\ncumec_wide_ts |&gt; \n  select(Date, Type, bcPukaki) |&gt; \n  mutate(Year = year(Date),\n         Quarter = paste0(\"Q\",quarter(Date)),\n         Week = week(Date)) |&gt; \n  filter(Type == \"Actual\") |&gt; \n  ggplot(aes(x = bcPukaki, group = Quarter)) +\ngeom_density(aes(col = Quarter), binwidth = 0.1)\n\nWarning in geom_density(aes(col = Quarter), binwidth = 0.1): Ignoring unknown\nparameters: `binwidth`",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Exploration</span>"
    ]
  },
  {
    "objectID": "single_scheme.html",
    "href": "single_scheme.html",
    "title": "3  Single Scheme",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Single Scheme</span>"
    ]
  },
  {
    "objectID": "dual_scheme.html",
    "href": "dual_scheme.html",
    "title": "4  Dual Scheme",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Dual Scheme</span>"
    ]
  },
  {
    "objectID": "multi_scheme.html",
    "href": "multi_scheme.html",
    "title": "5  Multi Scheme",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multi Scheme</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "6  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]